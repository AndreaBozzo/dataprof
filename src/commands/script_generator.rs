use anyhow::Result;
use std::collections::HashSet;
use std::fs;
use std::path::Path;

use dataprof::analysis::{
    MlReadinessLevel, MlReadinessScore, MlRecommendation, RecommendationPriority,
};

/// Generates a complete preprocessing Python script from ML recommendations
pub fn generate_preprocessing_script(
    ml_score: &MlReadinessScore,
    output_path: &Path,
    data_file_path: &str,
) -> Result<()> {
    let script_content = create_preprocessing_script_content(ml_score, data_file_path)?;
    fs::write(output_path, script_content)?;
    Ok(())
}

/// Creates the content of a preprocessing Python script
fn create_preprocessing_script_content(
    ml_score: &MlReadinessScore,
    data_file_path: &str,
) -> Result<String> {
    let mut script = String::new();

    // Add header comment
    script.push_str(&format!(
        r#"#!/usr/bin/env python3
"""
Preprocessing Script for ML Pipeline
Generated by DataProf ML Readiness Assessment

Source data: {}
Overall ML Readiness: {:.1}% ({})
Generated {} recommendations with actionable code snippets
"""

"#,
        data_file_path,
        ml_score.overall_score,
        readiness_level_to_string(&ml_score.readiness_level),
        ml_score.recommendations.len()
    ));

    // Collect all imports
    let imports = collect_unique_imports(&ml_score.recommendations);
    for import in &imports {
        script.push_str(&format!("{}\n", import));
    }
    script.push('\n');

    // Add main function
    script.push_str(&format!(
        r#"def preprocess_data(input_file=r"{}"):
    """
    Preprocess data for ML based on DataProf recommendations.

    Args:
        input_file (str): Path to the input CSV file

    Returns:
        pandas.DataFrame: Preprocessed data ready for ML
    """
    print("üîÑ Loading data...")
    df = pd.read_csv(input_file)
    print(f"üìä Loaded data: {{df.shape[0]}} rows, {{df.shape[1]}} columns")

    original_shape = df.shape

"#,
        data_file_path
    ));

    // Add preprocessing steps from recommendations
    let mut step_number = 1;

    // Group recommendations by priority for better organization
    let critical_recs: Vec<_> = ml_score
        .recommendations
        .iter()
        .filter(|r| matches!(r.priority, RecommendationPriority::Critical))
        .collect();
    let high_recs: Vec<_> = ml_score
        .recommendations
        .iter()
        .filter(|r| matches!(r.priority, RecommendationPriority::High))
        .collect();
    let medium_recs: Vec<_> = ml_score
        .recommendations
        .iter()
        .filter(|r| matches!(r.priority, RecommendationPriority::Medium))
        .collect();

    if !critical_recs.is_empty() {
        script.push_str("    # ========== CRITICAL ISSUES (Must Fix) ==========\n");
        for rec in critical_recs {
            if let Some(code) = &rec.code_snippet {
                script.push_str(&format!(
                    "    # Step {}: {} ({})\n",
                    step_number,
                    rec.category,
                    priority_to_string(&rec.priority)
                ));
                script.push_str(&format!("    # {}\n", rec.description));
                script.push_str(&format!(
                    "    print(f\"‚ö†Ô∏è Step {}: {}\")\n",
                    step_number, rec.category
                ));

                // Indent the code properly and handle newlines
                let indented_code = indent_code(code, 4);
                script.push_str(&format!("    {}\n", indented_code));
                script.push_str("    \n");
                step_number += 1;
            }
        }
    }

    if !high_recs.is_empty() {
        script.push_str("    # ========== HIGH PRIORITY ==========\n");
        for rec in high_recs {
            if let Some(code) = &rec.code_snippet {
                script.push_str(&format!(
                    "    # Step {}: {} ({})\n",
                    step_number,
                    rec.category,
                    priority_to_string(&rec.priority)
                ));
                script.push_str(&format!("    # {}\n", rec.description));
                script.push_str(&format!(
                    "    print(f\"üîß Step {}: {}\")\n",
                    step_number, rec.category
                ));

                let indented_code = indent_code(code, 4);
                script.push_str(&format!("    {}\n", indented_code));
                script.push_str("    \n");
                step_number += 1;
            }
        }
    }

    if !medium_recs.is_empty() {
        script.push_str("    # ========== MEDIUM PRIORITY ==========\n");
        for rec in medium_recs {
            if let Some(code) = &rec.code_snippet {
                script.push_str(&format!(
                    "    # Step {}: {} ({})\n",
                    step_number,
                    rec.category,
                    priority_to_string(&rec.priority)
                ));
                script.push_str(&format!("    # {}\n", rec.description));
                script.push_str(&format!(
                    "    print(f\"üîÑ Step {}: {}\")\n",
                    step_number, rec.category
                ));

                let indented_code = indent_code(code, 4);
                script.push_str(&format!("    {}\n", indented_code));
                script.push_str("    \n");
                step_number += 1;
            }
        }
    }

    // Add return statement and summary
    script.push_str(&format!(
        r#"    final_shape = df.shape
    print(f"‚úÖ Preprocessing complete!")
    print(f"üìä Final data shape: {{final_shape[0]}} rows, {{final_shape[1]}} columns")
    print(f"üîÑ Shape change: {{original_shape}} ‚Üí {{final_shape}}")

    return df


def main():
    """Main function to run the preprocessing pipeline."""
    try:
        # Run preprocessing
        processed_df = preprocess_data()

        # Save processed data
        output_file = r"{}_preprocessed.csv"
        processed_df.to_csv(output_file, index=False)
        print(f"üíæ Saved preprocessed data to: {{output_file}}")

        # Display basic info about processed data
        print("\nüìã Processed Data Summary:")
        print(processed_df.info())

        if processed_df.shape[1] <= 20:  # Show describe for manageable number of columns
            print("\nüìä Statistical Summary:")
            print(processed_df.describe())

    except Exception as e:
        print(f"‚ùå Error during preprocessing: {{e}}")
        raise


if __name__ == "__main__":
    main()
"#,
        data_file_path.replace(".csv", "")
    ));

    Ok(script)
}

/// Collect unique imports from all recommendations
fn collect_unique_imports(recommendations: &[MlRecommendation]) -> Vec<String> {
    let mut imports_set = HashSet::new();

    for rec in recommendations {
        for import in &rec.imports {
            imports_set.insert(import.clone());
        }
    }

    let mut imports: Vec<String> = imports_set.into_iter().collect();
    imports.sort();
    imports
}

/// Convert RecommendationPriority enum to string
fn priority_to_string(priority: &RecommendationPriority) -> String {
    match priority {
        RecommendationPriority::Critical => "critical".to_string(),
        RecommendationPriority::High => "high".to_string(),
        RecommendationPriority::Medium => "medium".to_string(),
        RecommendationPriority::Low => "low".to_string(),
    }
}

/// Convert MlReadinessLevel enum to string
fn readiness_level_to_string(level: &MlReadinessLevel) -> String {
    match level {
        MlReadinessLevel::Ready => "Ready".to_string(),
        MlReadinessLevel::Good => "Good".to_string(),
        MlReadinessLevel::NeedsWork => "Needs Work".to_string(),
        MlReadinessLevel::NotReady => "Not Ready".to_string(),
    }
}

/// Indent code properly for Python functions
fn indent_code(code: &str, spaces: usize) -> String {
    let indent = " ".repeat(spaces);
    code.replace("\\n", "\n") // Convert escaped newlines to actual newlines
        .lines()
        .map(|line| {
            if line.trim().is_empty() {
                String::new()
            } else {
                format!("{}{}", indent, line)
            }
        })
        .collect::<Vec<_>>()
        .join("\n")
}
