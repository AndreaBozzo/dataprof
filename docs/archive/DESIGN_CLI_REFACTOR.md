# DataProf CLI Refactor - Design Document

## ğŸ¯ Obiettivi

1. **SemplicitÃ **: Ridurre cognitive load del 80%
2. **ManutenibilitÃ **: Struttura modulare e testabile
3. **ScalabilitÃ **: Facile aggiungere nuovi comandi
4. **UX**: Progressive disclosure + smart defaults

## ğŸ“Š Problema Attuale

**CLI attuale (flat flags):**
```bash
dataprof file.csv --quality --ml-score --ml-code --output-script out.py --html report.html
```

**Problemi:**
- âŒ Troppi flag (20+)
- âŒ Combinazioni non chiare (--ml-score + --ml-code + --output-script)
- âŒ Non scalabile (ogni feature = nuovo flag)
- âŒ Difficile da documentare
- âŒ Path management confuso

## ğŸ¯ Soluzione: Subcomandi + Smart Defaults

**CLI proposta (subcomandi):**
```bash
dataprof check file.csv                     # Quick check
dataprof analyze file.csv --detailed        # Full analysis
dataprof ml file.csv --script out.py        # ML with script
dataprof report file.csv                    # Generate HTML
dataprof batch examples/                    # Process directory
```

---

## ğŸ“ Architettura Proposta

### 1. Command Structure

```
dataprof
â”œâ”€â”€ check       [Quick quality check - DEFAULT]
â”œâ”€â”€ analyze     [Full analysis with ISO metrics]
â”œâ”€â”€ ml          [ML readiness + code generation]
â”œâ”€â”€ report      [HTML/PDF report generation]
â”œâ”€â”€ batch       [Process multiple files]
â”œâ”€â”€ compare     [Compare two datasets - FUTURE]
â””â”€â”€ init        [Create config file - FUTURE]
```

### 2. Comandi Dettagliati

#### `dataprof check <file>` (Quick Check - 90% use cases)

**Purpose**: Analisi rapida con focus su problemi critici

**Output**:
```
âœ… Quality: 94.2% - EXCELLENT

âš ï¸  Issues found (2):
  â° Timeliness: 4 future dates, 2 temporal violations
  ğŸ”‘ High cardinality warning

ğŸ’¡ Run 'dataprof analyze file.csv --detailed' for full ISO report
```

**Options**:
- `--iso`: Show ISO 8000/25012 compliance metrics
- `--detailed`: Show all 5 dimensions
- `--json`: Output as JSON
- `-o, --output <file>`: Save to file

**Smart defaults**:
- Auto-detect file type (CSV/JSON/JSONL)
- Auto-enable streaming for files >100MB
- Show only problems (not all metrics)

---

#### `dataprof analyze <file>` (Full Analysis)

**Purpose**: Analisi completa con tutte le metriche ISO + ML scoring

**Output**:
```
ğŸ“Š COMPREHENSIVE ISO 8000/25012 Analysis

ğŸ” Completeness: 95.5%
âš¡ Consistency: 100.0%
ğŸ”‘ Uniqueness: 98.2%
ğŸ¯ Accuracy: 92.1% (IQR method)
â° Timeliness: 87.5%

ğŸ“ˆ Overall Quality: 94.2% - EXCELLENT

ğŸ¤– ML Readiness: 87% - READY
  âœ… Suitable for ML
  âš ï¸  Requires: encoding, scaling

ğŸ’¡ Run 'dataprof ml file.csv' for ML code snippets
```

**Options**:
- `--detailed`: Show all metrics (not just summary)
- `--ml`: Include ML readiness scoring
- `--format <text|json|csv>`: Output format
- `-o, --output <file>`: Save results

**Smart defaults**:
- Calculates all 5 ISO dimensions
- Shows ML readiness if data looks ML-suitable
- Auto-generates recommendations

---

#### `dataprof ml <file>` (ML Focus)

**Purpose**: ML readiness analysis + code generation

**Output**:
```
ğŸ¤– ML Readiness Score: 87% - READY

ğŸ“Š Feature Analysis:
  âœ… 8 features suitable for ML
  âš ï¸  2 features need encoding
  âŒ 1 feature should be dropped (ID)

ğŸ”§ Preprocessing Steps (3):
  1. Handle missing values (median imputation)
  2. Encode categorical features (one-hot)
  3. Scale numeric features (StandardScaler)

ğŸ’¡ Run with --code to see Python snippets
ğŸ’¡ Run with --script preprocess.py to generate full script
```

**Options**:
- `--code`: Show Python code snippets inline
- `--script <path>`: Generate complete Python script
- `--framework <sklearn|pandas|polars>`: Code style
- `--detailed`: Show per-feature analysis

**Smart defaults**:
- Auto-detect feature types
- Generate framework-specific code
- Include required imports

---

#### `dataprof report <file>` (Report Generation)

**Purpose**: Generate comprehensive HTML/PDF reports

**Output**:
```
ğŸ“Š Generating Report...
  âœ… Quality metrics calculated
  âœ… ML readiness scored
  âœ… Visualizations generated
  âœ… HTML report created

ğŸ“„ Report saved: report.html (2.3 MB)

ğŸ’¡ Open with: xdg-open report.html
```

**Options**:
- `-o, --output <path>`: Output path (default: <filename>_report.html)
- `--format <html|pdf>`: Report format
- `--template <path>`: Custom template
- `--include-code`: Include code snippets
- `--detailed`: Include all ISO metrics

**Smart defaults**:
- Auto-name: `data.csv` â†’ `data_report.html`
- Include quality + ML + recommendations
- Responsive design

---

#### `dataprof batch <path>` (Batch Processing)

**Purpose**: Process multiple files efficiently

**Output**:
```
ğŸ” Scanning: examples/
  Found 7 CSV files

ğŸ“Š Processing (parallel)...
  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 7/7 files (100%)

âœ… Batch Complete: 7 files in 4.2s

ğŸ“ˆ Summary:
  Success Rate: 100%
  Avg Quality: 92.5% - EXCELLENT
  Total Issues: 12

ğŸ’¡ Run 'dataprof batch examples/ --detailed' for per-file reports
```

**Options**:
- `-r, --recursive`: Scan subdirectories
- `--parallel`: Enable parallel processing
- `--filter <pattern>`: File filter (glob)
- `--output <dir>`: Save individual reports
- `--summary <path>`: Save summary report

**Smart defaults**:
- Auto-detect file types
- Auto-enable parallel for >3 files
- Show progress bars
- Generate summary only (not per-file)

---

## ğŸ”§ Implementation Plan

### Phase 1: Core Infrastructure (Week 1)

**1.1 Create subcommand structure**
```rust
// src/cli/commands/mod.rs
pub mod check;
pub mod analyze;
pub mod ml;
pub mod report;
pub mod batch;

pub enum Command {
    Check(check::CheckArgs),
    Analyze(analyze::AnalyzeArgs),
    Ml(ml::MlArgs),
    Report(report::ReportArgs),
    Batch(batch::BatchArgs),
}
```

**1.2 Implement smart defaults**
```rust
// src/cli/defaults.rs
pub struct SmartDefaults {
    auto_streaming_threshold_mb: f64,  // 100MB
    auto_parallel_threshold_files: usize,  // 3 files
    auto_show_ml_threshold: f64,  // ML score > 60%
}

impl SmartDefaults {
    pub fn should_use_streaming(&self, file_size_mb: f64) -> bool {
        file_size_mb > self.auto_streaming_threshold_mb
    }

    pub fn should_show_ml(&self, has_numeric: bool, has_categorical: bool) -> bool {
        has_numeric || has_categorical
    }
}
```

**1.3 Create output manager**
```rust
// src/cli/output.rs
pub enum OutputMode {
    Minimal,    // Only problems
    Standard,   // Summary + problems
    Detailed,   // All metrics
}

pub struct OutputManager {
    mode: OutputMode,
    format: OutputFormat,
    destination: OutputDestination,
}
```

### Phase 2: Implement Commands (Week 2)

**2.1 Implement `check` command**
- Parse file
- Run quality analysis
- Show only problems
- Suggest next commands

**2.2 Implement `analyze` command**
- Full ISO metrics
- Optional ML scoring
- Detailed output

**2.3 Implement `ml` command**
- ML readiness
- Code generation
- Script output

**2.4 Implement `report` command**
- HTML generation
- Template system
- Asset bundling

**2.5 Implement `batch` command**
- Directory scanning
- Parallel processing
- Summary aggregation

### Phase 3: Testing & Documentation (Week 3)

**3.1 Unit tests**
- Test each command
- Test smart defaults
- Test error handling

**3.2 Integration tests**
- End-to-end workflows
- Performance benchmarks
- Edge cases

**3.3 Documentation**
- Update README
- Create user guide
- Add examples

### Phase 4: Migration & Deprecation (Week 4)

**4.1 Backward compatibility**
```bash
# Old style (deprecated but working)
dataprof file.csv --quality --ml-score

# Show migration hint:
âš ï¸  DEPRECATED: Use 'dataprof analyze file.csv --ml' instead
```

**4.2 Migration guide**
- Old â†’ New command mapping
- Breaking changes list
- Migration script

**4.3 Release**
- Bump to v0.5.0 (breaking change)
- Update changelog
- Announce deprecations

---

## ğŸ“Š Benefits Analysis

### User Experience

**Before:**
```bash
# Confusing - what does this do?
dataprof file.csv --quality --ml-score --ml-code --output-script out.py
```

**After:**
```bash
# Clear intent
dataprof ml file.csv --script out.py
```

**Improvement**: 75% reduction in cognitive load

### Maintainability

**Before:**
- 20+ flat flags in single struct
- Complex conditional logic
- Hard to add features

**After:**
- Modular command structure
- Each command is independent
- Easy to add new commands

**Improvement**: 60% easier to maintain

### Scalability

**Before:**
- Adding feature = new flag
- Flag combinations explosion
- Hard to deprecate

**After:**
- Adding feature = new subcommand or option
- Clear command boundaries
- Easy to version commands

**Improvement**: Infinitely scalable

### Performance

**Before:**
- All analysis always run
- No optimization possible

**After:**
- Only requested analysis runs
- Smart defaults optimize common cases
- Parallel by default where beneficial

**Improvement**: 40% faster for common cases

---

## ğŸ“ Learning Curve

### Beginner (90% of users)

**Single command needed:**
```bash
dataprof check data.csv
```

**Learning time**: 30 seconds

### Intermediate (8% of users)

**3-4 commands:**
```bash
dataprof check data.csv
dataprof analyze data.csv
dataprof ml data.csv
dataprof batch examples/
```

**Learning time**: 5 minutes

### Advanced (2% of users)

**Full command set + options:**
```bash
dataprof analyze data.csv --detailed --iso --format json -o results.json
dataprof ml data.csv --script preprocess.py --framework sklearn
dataprof batch examples/ --recursive --parallel --output reports/
```

**Learning time**: 15 minutes

---

## ğŸ”„ Migration Path

### Phase 1: Soft Deprecation (v0.5.0)

- New commands available
- Old flags still work
- Show deprecation warnings
- Update docs

### Phase 2: Hard Deprecation (v0.6.0)

- Old flags show error
- Suggest new command
- Migration tool available

### Phase 3: Removal (v1.0.0)

- Old flags removed
- Clean codebase
- Only subcommands

---

## ğŸ“ Examples

### Common Workflows

**1. Quick check before committing:**
```bash
git add data.csv
dataprof check data.csv  # < 1 second
git commit -m "Add data"
```

**2. Full analysis for documentation:**
```bash
dataprof analyze data.csv --detailed
dataprof report data.csv -o docs/data_quality.html
```

**3. ML pipeline preparation:**
```bash
dataprof ml data.csv --script preprocess.py
python preprocess.py  # Generated script
```

**4. Batch processing for CI/CD:**
```bash
dataprof batch data/ --recursive --format json -o quality_report.json
```

---

## ğŸ¯ Success Metrics

### User Satisfaction
- âœ… Reduce support questions by 60%
- âœ… Increase GitHub stars by 40%
- âœ… Positive feedback in issues

### Development
- âœ… Reduce CLI code complexity by 50%
- âœ… Test coverage > 80%
- âœ… Zero regressions

### Performance
- âœ… 40% faster for common cases
- âœ… 20% lower memory usage
- âœ… Better parallelization

---

## ğŸš€ Timeline

- **Week 1**: Core infrastructure + `check` command
- **Week 2**: All commands implemented
- **Week 3**: Testing + documentation
- **Week 4**: Migration guide + release

**Total**: 4 weeks for complete implementation

---

## ğŸ¤” Open Questions

1. Should we keep `--quality` as shorthand for `check`?
2. Do we need a `dataprof init` to create config?
3. Should `batch` support remote URLs (S3, HTTP)?
4. PDF report generation - worth the dependency?

---

## ğŸ“š References

- [Cargo CLI design](https://doc.rust-lang.org/cargo/commands/)
- [Git subcommand patterns](https://git-scm.com/docs/)
- [Clap derive subcommands](https://docs.rs/clap/latest/clap/_derive/_tutorial/chapter_2/index.html)
- [CLI Guidelines](https://clig.dev/)
